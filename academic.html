<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lionel Wong @ MIT</title>

  <meta name="author" content="Lionel Wong">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="academic_stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:left">
                    <name>Lionel Wong</name>
                  </p>
                  <p>
                    Welcome to my academic website! My weirder and more inscrutable site including fiction, audio
                    reporting, and clocks is <a href="https://web.mit.edu/zyzzyva/www/">here</a>.<br><br>
                    I am a fifth year PhD student at MIT, advised by Josh Tenenbaum in the <a
                      href="http://cocosci.mit.edu/">Computational Cognitive Science</a> group. Previously I've interned
                    at <a href="https://flatiron.com/">Flatiron Health</a> and Google (for <a
                      href="https://research.google/">Research</a>, <a
                      href="https://classroom.google.com/u/0/h">Classroom</a>, and <a
                      href="https://www.google.com/glass/start/">Glass</a>), and did a brief but wonderful stint at the
                    <a href="https://www.wnycstudios.org/podcasts/nancy">Nancy podcast</a> for WNYC. I am grateful for
                    support from an MIT Presidential Fellowship. I earned my B.S. and M.S. in computer science at
                    Stanford.<br><br>

                    I am interested in <b>modeling intelligent systems that use language</b>. My research primarily uses
                    program synthesis to study how we make meaning from language, and how language in turn scaffolds how
                    we learn new concepts, plan, and understand the physical and visual world.<br><br>

                    I also care a lot about the ethical and societal impact of artificial intelligence and cognitive
                    science research -- what we do, and who gets to do it. I formerly co-organized the <a
                      href="https://sites.google.com/view/mit-bcs-philosophy/home">BCS Philosophy Circle</a> and am
                    proud to serve on the MIT <a
                      href="https://diversity.mit.edu/about/committee-race-and-diversity-crd">Institute Committee on
                      Race and Diversity</a>.

                    <br><br>
                    I use they/them pronouns and previously published professionally as Catherine Wong ðŸ’¯. Publications
                    that haven't been updated yet are cited below in their original authorship list and form.
                    <br><br>
                    Google Scholar contains the most up-to-date and accurate list of publications.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zyzzyva@mit.edu">zyzzyva@mit.edu</a> &nbsp/&nbsp
                    <a href="data/Catherine_Wong_cv.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=KssJcIAAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/CatherineWong?tab=repositories">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/CathyWong_profile.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/CathyWong_profile.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications and Manuscripts in Preparation</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2022</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Identifying concept libraries from language about object structure.</papertitle>
                  </strong>
                  <br>
                  <strong>C. Wong*</strong>, W. McCarthy G. Grand, et. al
                  <br>
                  <em>CogSci</em>, 2022
                  <a href="https://arxiv.org/abs/2205.05666">paper</a> [arxiv],
                  <a href="https://github.com/cogtoolslab/lax-cogsci22">code</a> [git]
                  <a href="https://sites.google.com/view/language-abstraction/home">extras</a> [website]

                  <br>
                  <p></p>
                  <p>We introduce a large scale language dataset comprised of 2K labeled drawings and block towers in
                    order to study the lexicon of parts people name in language. We find that people's vocabularies can
                    be modeled by program libraries which jointly optimize for the library size and the description
                    length of any one object represented in that library.</p>
                </td>
              </tr>



              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2022</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Structured, flexible, and robust: benchmarking and improving large language models
                      towards more human-like behavior in out- of-distribution reasoning tasks.</papertitle>
                  </strong>
                  <br>
                  K. Collins*, <strong>C. Wong*</strong>, J. Feng, M. Wei, J. Tenenbaum
                  <br>
                  <em>CogSci</em>, 2022
                  <a href="https://arxiv.org/abs/2205.05718">paper</a> [arxiv],
                  <a href="https://github.com/collinskatie/structured_flexible_and_robust">code</a> [git]
                  <br>
                  <p></p>
                  <p>We introduce a challenge benchmark for comparing humans and large language models on increasingly
                    constrained planning and explanation tasks, and a new hybrid Parse-and-Solve model that translates
                    language into formal goal programs to improve planning robustness.</p>
                </td>
              </tr>




              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2021</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Leveraging language to learn program abstractions and search heuristics.</papertitle>
                  </strong>
                  <br>
                  <strong>C. Wong</strong>, K. Ellis, J. Andreas, J. Tenenbaum
                  <br>
                  <em>ICML</em>, 2021
                  <a href="https://arxiv.org/abs/2106.11053">paper</a> [arxiv],
                  <a href="https://github.com/ellisk42/ec/tree/icml_2021_supplement">code</a> [git]
                  <br>
                  <p></p>
                  <p>We show that joint generative models between language and programs can be used to more quickly and
                    effectively learn program abstractions and synthesis search heuristics.</p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2021</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>DreamCoder: bootstrapping inductive program synthesis with wake-sleep library learning.
                    </papertitle>
                  </strong>
                  <br>
                  K. Ellis, <strong>C. Wong</strong>, M. Nye, M. Sable-Meyer, L. Cary, L. Morales, L. Hewitt, A.
                  Solar-Lezama, J. Tenenbaum
                  <br>
                  <em> PLDI </em> 2021.
                  <a href="https://dl.acm.org/doi/abs/10.1145/3453483.3454080">paper</a> [arxiv],
                  <a href="https://arxiv.org/abs/2006.08381">paper</a> [arxiv-extended-version],
                  <a href="https://github.com/ellisk42/ec">code</a> [git]
                  <br>
                  <p></p>
                  <p>We present a neurosymbolic program induction system that alternates between writing programs that
                    solve tasks and building libraries of abstractions from learned programs.</p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2021</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Language as a bootstrap for compositional visual reasoning.</papertitle>
                  </strong>
                  <br>
                  <strong>C. Wong</strong>, Y. Friedman, J. Andreas, J. Tenenbuam
                  <br>
                  <em>CogSci</em>, 2021
                  <a href="https://escholarship.org/uc/item/71t3f3qq">abstract</a> [cogsci]
                  <br>
                  <p></p>
                  <p>We ask people to solve increasingly abstract CLEVR-like visual reasoning tasks, and compare
                    performance between people solving inductive tasks with no language and people given additional
                    language annotations in an artificial compositional grammar.</p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2020</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Concept grounding of ARC with iterated human communications.</papertitle>
                  </strong>
                  <br>
                  S. Acquaviva, Y. Pu, <strong>C. Wong</strong>, M.H. Tessler, M. Nye
                  <br>
                  <em>AAAI Symposium on Conceptual Abstraction</em>, 2020
                  <br>
                  <p></p>
                  <p>We leverage chains of people solving and describing conceptual reasoning tasks to suggest what
                    concepts belong in a DSL.</p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2019</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>From mental representations to neural codes: a multi-level approach.</papertitle>
                  </strong>
                  <br>
                  J. Gauthier*, J. Loula*, E. Pollock*, T. Wilson* <strong>C. Wong*</strong>, *Equal contributors.
                  <br>
                  <em> Behavioral Brain Sciences </em> 2019.
                  <a
                    href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/from-mental-representations-to-neural-codes-a-multilevel-approach/484046589CE54F9DF872D602A70683F2">paper</a>
                  [BBS]
                  <br>
                  <p></p>
                  <p>We argue that a computational approach to mental representation can constrain how we analyze
                    behavior and neural patterns.</p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <b>2018</b>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>
                    <papertitle>Transfer learning with AutoML.</papertitle>
                  </strong>
                  <br>
                  <strong>C. Wong</strong>, N. Houlsby, Y. Lu, A. Gesmundo
                  <br>
                  <em> NeurIPS </em> 2018.
                  <a href="https://papers.nips.cc/paper/8056-transfer-learning-with-neural-automl.pdf">paper</a>
                  [NeurIPS]
                  <br>
                  <p></p>
                  <p>We show that transfer learning across tasks can reduce the search time of automatically building ML
                    architectures by over an order of magnitude.</p>
                </td>
              </tr>

            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>