<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Catherine Wong @ MIT</title>
  
  <meta name="author" content="Catherine Wong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="academic_stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left">
                <name>Cathy Wong</name>
              </p>
              <p>
                Welcome to my academic website! My weirder and more inscrutable site including fiction, audio reporting, and clocks is <a href="https://web.mit.edu/zyzzyva/www/">here</a>.<br><br> 
                I am a third year PhD student at MIT, advised by Josh Tenenbaum in the <a href="http://cocosci.mit.edu/">Computational Cognitive Science</a> group. Previously I've interned at <a href="https://flatiron.com/">Flatiron Health</a> and Google (for <a href="https://research.google/">Research</a>, <a href="https://classroom.google.com/u/0/h">Classroom</a>, and <a href="https://www.google.com/glass/start/">Glass</a>), and did a brief but wonderful stint at the <a href="https://www.wnycstudios.org/podcasts/nancy">Nancy podcast</a> for WNYC. I am grateful for support from an MIT Presidential Fellowship. I earned my B.S. and M.S. in computer science at Stanford.<br><br> 
                
                I am interested in <b>how computers can understand language as flexibly as people do</b>, and how people do it in the first place. My research uses program synthesis, planning, and physical simulation to study how language is learned and understood across different world and linguistic contexts.<br><br> 
                
                I also care a lot about the ethical and societal impact of artificial intelligence and cognitive science research -- what we do, and who gets to do it. I co-organize the <a href="https://sites.google.com/view/mit-bcs-philosophy/home">BCS Philosophy Circle</a> and am proud to serve on the  MIT <a href="https://diversity.mit.edu/about/committee-race-and-diversity-crd">Institute Committee on Race and Diversity</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:catwong@mit.edu">catwong@mit.edu</a> &nbsp/&nbsp
                <a href="data/Catherine_Wong_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=KssJcIAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/CatherineWong?tab=repositories">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/CathyWong_profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/CathyWong_profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications and Manuscripts in Preparation</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <b>2020</b>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Leveraging natural language for program search and abstraction learning.</papertitle>
              </strong>
              <br>
              <strong>C. Wong</strong>, K. Ellis, J. Andreas, J. Tenenbaum
              <br>
              <em>under review</em>; oral version at <em>AAAI Symposium on Conceptual Abstraction</em>, 2020
              <br>
              <p></p>
              <p>We show that inducing joint grammars over natural language annotations and programs can bootstrap faster program search and abstraction learning.</p>
            </td>
          </tr> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <b>2020</b>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Concept grounding of ARC with iterated human communications.</papertitle>
              </strong>
              <br>
              S. Acquaviva, Y. Pu, <strong>C. Wong</strong>, M.H. Tessler, M. Nye 
              <br>
              <em>AAAI Symposium on Conceptual Abstraction</em>, 2020
              <br>
              <p></p>
              <p>We leverage chains of people solving and describing conceptual reasoning tasks to suggest what concepts belong in a DSL.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <b>2020</b>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning.</papertitle>
              </strong>
              <br>
              K. Ellis, <strong>C. Wong</strong>, M. Nye, M. Sable-Meyer, L. Cary, L. Morales, L. Hewitt, A. Solar-Lezama, J. Tenenbaum
              <br>
              <em> ArXiv </em> 2020.
              <a href="https://arxiv.org/abs/2006.08381">paper</a> [arxiv],
              <a href="https://github.com/ellisk42/ec">code</a> [git]
              <br>
              <p></p>
              <p>We present a neurosymbolic program induction system that alternates between writing programs that solve tasks and building libraries of abstractions from learned programs.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <b>2019</b>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>From mental representations to neural codes: a multi-level approach.</papertitle>
              </strong>
              <br>
              J. Gauthier*, J. Loula*, E. Pollock*,  T. Wilson* <strong>C. Wong*</strong>, *Equal contributors.
              <br>
              <em> Behavioral Brain Sciences  </em> 2019.
              <a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/from-mental-representations-to-neural-codes-a-multilevel-approach/484046589CE54F9DF872D602A70683F2">paper</a> [BBS]
              <br>
              <p></p>
              <p>We argue that a computational approach to mental representation can constrain how we analyze behavior and neural patterns.</p>
            </td>
          </tr> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <b>2018</b>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Transfer learning with AutoML.</papertitle>
              </strong>
              <br>
              <strong>C. Wong</strong>, N. Houlsby, Y. Lu, A. Gesmundo
              <br>
              <em> NeurIPS </em> 2018.
              <a href="https://papers.nips.cc/paper/8056-transfer-learning-with-neural-automl.pdf">paper</a> [NeurIPS]
              <br>
              <p></p>
              <p>We show that transfer learning across tasks can reduce the search time of automatically building ML architectures by over an order of magnitude.</p>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
